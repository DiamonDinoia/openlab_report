The results of all the tests performed are summarized in the table \ref{tab:speedup} below. There are two important things to notice: first, with improvements applied to the CPU version a speed up of additional $\bm{38\%}$ was achieved. In case of CPU, increasing the number of channels does not affect the speedup, because all the versions are single threaded, therefore an approximately uniform improvement is observed. Second of all, by porting to the GPU a speedup of a factor of $\bm{2.67}$ was achieved for the case of $\bm{~65K}$ channels (with trivial parallelization across all the channels). Important to note that for the GPU, a different trend is observed (increase up to ~8K and then a slow down, and an increase again), as expected, due to the parallel nature of the architecture.

\begin{table}[H]
  \caption{Speedup achieved after applying all the optimizations.}
  \label{tab:speedup}
\begin{tabular}{lrrrrrrr}
\toprule
channels &  1024  &  2048  &  4096  &  8192  &  16384 &  32768 &  65536 \\
\midrule
legacy\_multifit\_cpu &   1.00 &   1.00 &   1.00 &   1.00 &   1.00 &   1.00 &   1.00 \\
legacy\_multifit\_gpu &   0.62 &   1.22 &   1.77 &   2.09 &   1.89 &   2.10 &   2.23 \\
multifit\_cpu        &   1.25 &   1.38 &   1.35 &   1.35 &   1.33 &   1.34 &   1.34 \\
multifit\_gpu        &   0.96 &   1.57 &   2.09 &   2.56 &   2.31 &   2.54 &   2.67 \\
multifit\_gpu\_swap   &   0.42 &   0.73 &   1.10 &   1.15 &   1.11 &   1.21 &   1.23 \\
multifit\_cpu\_swap   &   0.45 &   0.48 &   0.51 &   0.50 &   0.50 &   0.50 &   0.50 \\
\bottomrule
\end{tabular}
\end{table}
There are few things left to try, some are architecture dependent and some are algorithmic:
\begin{itemize}
  \item \textbf{GPU}: Dynamic parallelism to better exploit the available resources.
  \item \textbf{GPU}: Parallelise matrix operations further, however that needs to be properly measured as matrices being used are quite small.
  \item \textbf{Algorithmic}: Update the Cholesky instead of recomputing it.

\end{itemize}